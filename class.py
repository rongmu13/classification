import io
import numpy as np
import pandas as pd
import streamlit as st
from typing import Dict

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.decomposition import PCA
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report
)
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

import matplotlib.pyplot as plt


st.set_page_config(page_title="ğŸ§ª è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿åˆ†é¡ã‚¢ãƒ—ãƒªï¼ˆExcelï¼‰", layout="wide")
st.title("ğŸ§ª è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿åˆ†é¡ã‚¢ãƒ—ãƒªï¼ˆExcelï¼‰")

st.markdown("""
**ä½¿ã„æ–¹**  
1) Excel ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆ**1åˆ—ç›®ï¼å…ƒãƒ©ãƒ™ãƒ«**ã€ä»¥é™ï¼æ•°å€¤ã®ç‰¹å¾´é‡ï¼‰ã€‚  
2) ç›®çš„ã‚¯ãƒ©ã‚¹æ•°ï¼ˆ2/3/4/5ï¼‰ã‚’é¸ã³ã€**ã€Œå…ƒãƒ©ãƒ™ãƒ« â†’ æ–°ãƒ©ãƒ™ãƒ«(0..K-1)ã€** ã‚’å‰²ã‚Šå½“ã¦ã€‚  
3) ä½¿ã†ç‰¹å¾´é‡ãƒ»åˆ†é¡å™¨ãƒ»PCA ã®æœ‰ç„¡ã‚’é¸ã¶ã€‚  
4) **ã€Œå­¦ç¿’ã—ã¦è©•ä¾¡ã€** ã‚’ã‚¯ãƒªãƒƒã‚¯ã€‚  
""")

# ---- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ----
st.sidebar.header("âš™ï¸ è¨­å®š")

test_size = st.sidebar.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å‰²åˆ", 0.1, 0.5, 0.2, 0.05)
random_state = st.sidebar.number_input("ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ (random_state)", value=42, step=1)
use_pca = st.sidebar.checkbox("PCA ã‚’ä½¿ç”¨ï¼ˆæœ¨ç³»ãƒ¢ãƒ‡ãƒ«ä»¥å¤–ï¼‰", value=False)
pca_var = st.sidebar.slider("PCA ç´¯ç©å¯„ä¸ç‡", 0.80, 0.99, 0.95, 0.01)

clf_name = st.sidebar.selectbox(
    "åˆ†é¡å™¨ã‚’é¸æŠ",
    ["KNN", "ç·šå½¢SVM", "SVMï¼ˆRBFï¼‰", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°", "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ"]
)

# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
if clf_name == "KNN":
    knn_k = st.sidebar.slider("KNN: è¿‘å‚æ•° (n_neighbors)", 1, 25, 5, 1)
elif clf_name == "ç·šå½¢SVM":
    linsvm_C = st.sidebar.slider("ç·šå½¢SVM: C", 0.01, 10.0, 1.0, 0.01)
elif clf_name == "SVMï¼ˆRBFï¼‰":
    rbf_C = st.sidebar.slider("SVMï¼ˆRBFï¼‰: C", 0.01, 10.0, 1.0, 0.01)
elif clf_name == "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°":
    logreg_C = st.sidebar.slider("ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°: C", 0.01, 10.0, 1.0, 0.01)
elif clf_name == "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ":
    rf_n = st.sidebar.slider("ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ: n_estimators", 50, 500, 300, 50)
    rf_depth = st.sidebar.slider("ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ: max_depthï¼ˆNone=0ï¼‰", 0, 50, 0, 1)

st.sidebar.divider()
st.sidebar.caption("æ¬ æå€¤ã¯åˆ—ã®ä¸­å¤®å€¤ã§è£œå®Œã€‚éæœ¨ç³»ãƒ¢ãƒ‡ãƒ«ã¯æ¨™æº–åŒ–ã‚’å®Ÿæ–½ã€‚ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã§ã¯å¤šãã®ãƒ¢ãƒ‡ãƒ«ã§ class_weight='balanced' ã‚’ä½¿ç”¨ï¼ˆKNN ã‚’é™¤ãï¼‰ã€‚")

# ---- ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ› ----
uploaded = st.file_uploader("ğŸ“¤ Excel ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.xlsxï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"])
if uploaded is None:
    st.info("Excel ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚**1åˆ—ç›®ã¯å…ƒãƒ©ãƒ™ãƒ«**ã€ä»¥é™ã¯æ•°å€¤ã®ç‰¹å¾´é‡ã§ã™ã€‚")
    st.stop()

# Excel èª­ã¿è¾¼ã¿
try:
    bytes_data = uploaded.read()
    xls = pd.ExcelFile(io.BytesIO(bytes_data))
    sheet_name = st.selectbox("ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚’é¸æŠ", xls.sheet_names)
    df = pd.read_excel(io.BytesIO(bytes_data), sheet_name=sheet_name)
except Exception as e:
    st.error(f"Excel ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸï¼š{e}")
    st.stop()

if df.shape[1] < 2:
    st.error("å°‘ãªãã¨ã‚‚2åˆ—ãŒå¿…è¦ã§ã™ï¼š1åˆ—ç›®ï¼å…ƒãƒ©ãƒ™ãƒ«ã€ãã®å¾Œã¯ç‰¹å¾´é‡ã€‚")
    st.stop()

st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
st.dataframe(df.head(), use_container_width=True)

# åˆ—ã®è­˜åˆ¥
orig_label_col = df.columns[0]
feature_cols_all = [c for c in df.columns[1:]]

# ç‰¹å¾´é‡ã‚’æ•°å€¤ã¸å¼·åˆ¶å¤‰æ›ï¼ˆéæ•°å€¤ã¯ NaN ã¸ï¼‰
df_features = df[feature_cols_all].apply(pd.to_numeric, errors="coerce")

# æ¬ æå€¤ãƒ¬ãƒãƒ¼ãƒˆ
with st.expander("ğŸ” æ¬ æå€¤ãƒ¬ãƒãƒ¼ãƒˆ"):
    na_counts = df_features.isna().sum()
    st.write(na_counts.to_frame("NaN ä»¶æ•°"))
    st.caption("ç‰¹å¾´é‡ã®éæ•°å€¤ãƒ»ç©ºç™½ã¯ NaN ã«å¤‰æ›ã•ã‚Œã€å¾Œã§ä¸­å¤®å€¤ã§è£œå®Œã—ã¾ã™ã€‚")

# ---- ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚° ----
st.subheader("ğŸ¯ ãƒ©ãƒ™ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã¨åˆ†é¡è¨­å®š")
unique_orig_labels = pd.Series(df[orig_label_col].unique()).tolist()
unique_orig_labels_sorted = sorted(unique_orig_labels, key=lambda x: str(x))

num_classes = st.radio("ç›®çš„ã‚¯ãƒ©ã‚¹æ•°", [2, 3, 4, 5], horizontal=True)

st.write("å„ **å…ƒãƒ©ãƒ™ãƒ«å€¤** ã«å¯¾ã—ã¦ã€æ–°ã—ã„ **ç›®çš„ãƒ©ãƒ™ãƒ«ï¼ˆ0..K-1ï¼‰** ã‚’å‰²ã‚Šå½“ã¦ã¦ãã ã•ã„ï¼š")
mapping: Dict = {}
cols = st.columns(2)
for idx, val in enumerate(unique_orig_labels_sorted):
    with cols[idx % 2]:
        new_lab = st.selectbox(
            f"å…ƒãƒ©ãƒ™ãƒ« {val} â†’",
            options=list(range(num_classes)),
            key=f"map_{idx}",
            index=0
        )
        mapping[val] = new_lab

st.caption(f"ç¾åœ¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼š{mapping}")

# æ–°ãƒ©ãƒ™ãƒ«ã®ä½œæˆ
try:
    y_new = df[orig_label_col].map(mapping)
except Exception as e:
    st.error(f"ãƒ©ãƒ™ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸï¼š{e}")
    st.stop()

mask_valid = y_new.notna()
dropped = (~mask_valid).sum()
if dropped > 0:
    st.warning(f"{dropped} è¡Œã§ãƒ©ãƒ™ãƒ«ãŒãƒãƒƒãƒ”ãƒ³ã‚°ã§ããªã‹ã£ãŸãŸã‚å‰Šé™¤ã—ã¾ã—ãŸã€‚ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
y = y_new[mask_valid].astype(int).values
X_all = df_features.loc[mask_valid].copy()

# ---- ç‰¹å¾´é‡é¸æŠ ----
st.subheader("ğŸ§© ç‰¹å¾´é‡ã®é¸æŠ")
chosen_feats = st.multiselect(
    "å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡åˆ—ã‚’é¸æŠï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
    options=feature_cols_all,
    default=feature_cols_all
)

if len(chosen_feats) == 0:
    st.error("å°‘ãªãã¨ã‚‚1ã¤ã®ç‰¹å¾´é‡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    st.stop()

X = X_all[chosen_feats].values

# å­¦ç¿’/ãƒ†ã‚¹ãƒˆåˆ†å‰²ï¼ˆå±¤åŒ–ï¼‰
try:
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
except ValueError as e:
    st.error(f"ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã«å¤±æ•—ã—ã¾ã—ãŸï¼š{e}ï¼ˆã‚ã‚‹ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã™ãã‚‹å¯èƒ½æ€§ï¼‰")
    st.stop()

# ---- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ----
num_classes_int = int(num_classes)
average_mode = "binary" if num_classes_int == 2 else "macro"
average_mode_jp = "äºŒå€¤" if average_mode == "binary" else "ãƒã‚¯ãƒ­"

def make_non_tree_pipeline(base_estimator):
    steps = [
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()),
    ]
    if use_pca and clf_name != "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ":
        steps.append(("pca", PCA(n_components=pca_var, svd_solver="full")))
    steps.append(("clf", base_estimator))
    return Pipeline(steps)

def make_tree_pipeline(base_estimator):
    return Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("clf", base_estimator)
    ])

# åˆ†é¡å™¨ã®ç”Ÿæˆ
if clf_name == "KNN":
    clf = make_non_tree_pipeline(KNeighborsClassifier(n_neighbors=knn_k))
elif clf_name == "ç·šå½¢SVM":
    clf = make_non_tree_pipeline(LinearSVC(C=linsvm_C, class_weight="balanced", dual="auto"))
elif clf_name == "SVMï¼ˆRBFï¼‰":
    clf = make_non_tree_pipeline(SVC(C=rbf_C, kernel="rbf", class_weight="balanced", probability=True))
elif clf_name == "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°":
    clf = make_non_tree_pipeline(LogisticRegression(C=logreg_C, max_iter=2000, class_weight="balanced"))
elif clf_name == "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ":
    md = None if rf_depth == 0 else rf_depth
    clf = make_tree_pipeline(RandomForestClassifier(
        n_estimators=rf_n,
        max_depth=md,
        random_state=random_state,
        class_weight="balanced"
    ))
else:
    st.error("æœªçŸ¥ã®åˆ†é¡å™¨ã§ã™ã€‚")
    st.stop()

# ---- å­¦ç¿’ã¨è©•ä¾¡ ----
st.subheader("ğŸš€ å­¦ç¿’ã¨è©•ä¾¡")
if st.button("å­¦ç¿’ã—ã¦è©•ä¾¡", type="primary"):
    try:
        clf.fit(X_train, y_train)
    except Exception as e:
        st.error(f"å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸï¼š{e}")
        st.stop()

    y_pred = clf.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average=average_mode)

    left, right, right2 = st.columns(3)
    with left:
        st.metric("æ­£è§£ç‡ (Accuracy)", f"{acc:.4f}")
    with right:
        st.metric(f"F1ï¼ˆ{average_mode_jp}ï¼‰", f"{f1:.4f}")

    # äºŒå€¤åˆ†é¡ã®ã¿ ROC AUC
    if num_classes_int == 2:
        try:
            if hasattr(clf, "decision_function"):
                y_score = clf.decision_function(X_test)
            elif hasattr(clf, "predict_proba"):
                y_score = clf.predict_proba(X_test)[:, 1]
            else:
                y_score = None
            if y_score is not None:
                auc = roc_auc_score(y_test, y_score)
                with right2:
                    st.metric("ROC AUC", f"{auc:.4f}")
        except Exception:
            pass
    else:
        st.caption("å¤šã‚¯ãƒ©ã‚¹ã§ã¯ AUC ã¯æœªè¨ˆç®—ã§ã™ï¼ˆOVO/OVR ã«æ‹¡å¼µå¯èƒ½ï¼‰ã€‚")

    # æ··åŒè¡Œåˆ—
    cm = confusion_matrix(y_test, y_pred, labels=list(range(num_classes_int)))
    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation="nearest")
    ax.figure.colorbar(im, ax=ax)
    ax.set(
        xticks=np.arange(num_classes_int),
        yticks=np.arange(num_classes_int),
        xticklabels=[f"Pred {i}" for i in range(num_classes_int)],
        yticklabels=[f"True {i}" for i in range(num_classes_int)],
        ylabel="True label",
        xlabel="Predicted label",
        title="Confusion Matrix"
    )
    for i in range(num_classes_int):
        for j in range(num_classes_int):
            ax.text(j, i, cm[i, j], ha="center", va="center")
    st.pyplot(fig)

    # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆè‹±èªå‡ºåŠ›ï¼šsklearn æ¨™æº–ï¼‰
    st.subheader("ğŸ“„ åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ")
    cr = classification_report(y_test, y_pred, digits=4, zero_division=0)
    st.code(cr, language="text")

    # è§£é‡ˆå¯èƒ½æ€§
    st.subheader("ğŸ§­ è§£é‡ˆå¯èƒ½æ€§")
    try:
        if clf_name == "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ":
            final = clf.named_steps["clf"]
            importances = final.feature_importances_
            imp_df = pd.DataFrame({"feature": chosen_feats, "importance": importances}).sort_values("importance", ascending=False)
            st.dataframe(imp_df, use_container_width=True)
            fig2, ax2 = plt.subplots(figsize=(6, min(0.35*len(chosen_feats)+1, 10)))
            ax2.barh(imp_df["feature"][::-1], imp_df["importance"][::-1])
            ax2.set_title("Feature Importance (Random Forest)")
            st.pyplot(fig2)

        elif clf_name in ["ç·šå½¢SVM", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°"]:
            final = clf.named_steps["clf"]
            if hasattr(final, "coef_"):
                coef = final.coef_
                if num_classes_int == 2:
                    coef = coef[0]
                    names = chosen_feats
                    if use_pca:
                        st.warning("PCA ã‚’ä½¿ç”¨ä¸­ï¼šä¿‚æ•°ã¯ä½æ¬¡å…ƒç©ºé–“ã®ã‚‚ã®ã§ã™ã€‚å…ƒã®ç‰¹å¾´é‡ã¸ã®ç›´æ¥çš„ãªå¯¾å¿œã¯å¼±ããªã‚Šã¾ã™ã€‚")
                    coef_df = pd.DataFrame({"feature": names, "coef": coef if len(coef)==len(names) else np.nan})
                    coef_df = coef_df.sort_values("coef", key=np.abs, ascending=False)
                    st.dataframe(coef_df, use_container_width=True)
                    fig3, ax3 = plt.subplots(figsize=(6, min(0.35*len(chosen_feats)+1, 10)))
                    ax3.barh(coef_df["feature"][::-1], coef_df["coef"][::-1])
                    ax3.set_title("Linear Model Coefficients")
                    st.pyplot(fig3)
                else:
                    st.caption("å¤šã‚¯ãƒ©ã‚¹ã®ä¿‚æ•°ã¯ one-vs-rest ã®è¡Œåˆ—ã§ã™ï¼ˆè¡¨ã§ç¢ºèªã§ãã¾ã™ï¼‰ã€‚")
                    st.dataframe(pd.DataFrame(coef, columns=chosen_feats), use_container_width=True)
            else:
                st.caption("ã“ã®ãƒ¢ãƒ‡ãƒ«ã«ã¯ä¿‚æ•°æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.caption("KNN / SVMï¼ˆRBFï¼‰ã«ã¯ç›´æ¥ã®ç‰¹å¾´é‡é‡è¦åº¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    except Exception as e:
        st.warning(f"è§£é‡ˆå¯èƒ½æ€§ã®è¨ˆç®—ã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{e}")

st.divider()
st.caption("ãƒ’ãƒ³ãƒˆï¼šã‚ã‚‹ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«ãŒ 0 ã«ãªã‚‹å ´åˆã€ãƒ†ã‚¹ãƒˆå‰²åˆã‚’å°ã•ãã™ã‚‹ã‹ã€ã‚¯ãƒ©ã‚¹ã‚’çµ±åˆã—ã¦ãã ã•ã„ã€‚")




